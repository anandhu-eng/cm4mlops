#!/bin/bash

export CM_DOCKER_BUILD_ARGS="GID=\" $(id -g $USER) \" UID=\" $(id -u $USER) \" ${CM_DOCKER_BUILD_ARGS}"
export PYTHONPATH="/home/anandhu/CM/repos/local/cache/3bdb110d76bb4958/inference/vision/classification_and_detection/python:/home/anandhu/CM/repos/local/cache/3bdb110d76bb4958/inference/tools/submission:/home/anandhu/CM/repos/anandhu-eng@cm4mlops/script/get-mlperf-inference-utils:${PYTHONPATH}"
export CM_BUILD_DOCKERFILE="no"
export CM_CNNDM_ACCURACY_DTYPE="int32"
export CM_DOCKERFILE_WITH_PATH="/home/anandhu/CM/repos/anandhu-eng@cm4mlops/script/app-mlperf-inference/dockerfiles/ubuntu_22.04.Dockerfile"
export CM_DOCKER_BUILD_ARGS="--build-arg GID=\" $(id -g $USER) \" --build-arg UID=\" $(id -u $USER) \""
export CM_DOCKER_BUILD_CMD="docker build  --no-cache --build-arg GID=\" $(id -g $USER) \" --build-arg UID=\" $(id -u $USER) \" -f "/home/anandhu/CM/repos/anandhu-eng@cm4mlops/script/app-mlperf-inference/dockerfiles/ubuntu_22.04.Dockerfile" -t "local/cm-script-app-mlperf-inference-generic--reference--mixtral-8x7b--pytorch--cpu--test--r4.1-dev-default--offline:ubuntu-22.04-latest" ."
export CM_DOCKER_CACHE="no"
export CM_DOCKER_CACHE_ARG=" --no-cache"
export CM_DOCKER_CONTAINER_ID=""
export CM_DOCKER_DETACHED_MODE="yes"
export CM_DOCKER_EXTRA_RUN_ARGS=" --ulimit memlock=-1 --cap-add SYS_ADMIN --cap-add SYS_TIME --security-opt apparmor=unconfined --security-opt seccomp=unconfined"
export CM_DOCKER_IMAGE_BASE="ubuntu:22.04"
export CM_DOCKER_IMAGE_NAME=""
export CM_DOCKER_IMAGE_RECREATE="yes"
export CM_DOCKER_IMAGE_REPO="local"
export CM_DOCKER_IMAGE_TAG="ubuntu-22.04-latest"
export CM_DOCKER_IMAGE_TAG_EXTRA="-latest"
export CM_DOCKER_INTERACTIVE_MODE="no"
export CM_DOCKER_OS="ubuntu"
export CM_DOCKER_OS_VERSION="22.04"
export CM_DOCKER_PRE_RUN_COMMANDS="['cm pull repo']"
export CM_DOCKER_RUN_CMD="cm run script --tags=app,mlperf,inference,generic,_reference,_mixtral-8x7b,_pytorch,_cpu,_test,_r4.1-dev_default,_offline --quiet=true --env.CM_QUIET=yes --env.CM_MLPERF_IMPLEMENTATION=reference --env.CM_MLPERF_MODEL=mixtral-8x7b --env.CM_MLPERF_RUN_STYLE=test --env.CM_MLPERF_BACKEND=pytorch --env.CM_MLPERF_LOADGEN_MAX_BATCHSIZE=1 --env.CM_MLPERF_SUBMISSION_SYSTEM_TYPE=datacenter --env.CM_MLPERF_CLEAN_ALL=True --env.CM_MLPERF_DEVICE=cpu --env.CM_MLPERF_USE_DOCKER=True --env.CM_HW_NAME=gh_action --env.OUTPUT_BASE_DIR=/home/anandhu/gh_action_results --env.CM_MLPERF_LOADGEN_SCENARIO=Offline --env.CM_MLPERF_INFERENCE_SUBMISSION_DIR=/home/anandhu/gh_action_submissions --env.CM_MLPERF_SUBMITTER=MLCommons --env.CM_MLPERF_LOADGEN_TARGET_QPS=1 --env.CM_TEST_QUERY_COUNT=1 --env.CM_MLPERF_LOADGEN_COMPLIANCE=no --env.CM_MLPERF_SUBMISSION_RUN=yes --env.CM_RUN_MLPERF_ACCURACY=on --env.CM_RUN_SUBMISSION_CHECKER=yes --env.CM_TAR_SUBMISSION_DIR=yes --env.CM_MLPERF_SUBMISSION_GENERATION_STYLE=short --env.CM_MLPERF_LOADGEN_ALL_MODES=yes --env.CM_MLPERF_INFERENCE_VERSION=4.1-dev --env.CM_RUN_MLPERF_INFERENCE_APP_DEFAULTS=r4.1-dev_default --env.CM_MLPERF_LAST_RELEASE=v4.0 --env.CM_TMP_PIP_VERSION_STRING= --env.CM_MODEL=mixtral-8x7b --env.CM_MLPERF_CLEAN_SUBMISSION_DIR=yes --env.CM_RERUN=yes --env.CM_MLPERF_LOADGEN_EXTRA_OPTIONS= --env.CM_MLPERF_LOADGEN_MODE=performance --env.CM_MLPERF_LOADGEN_SCENARIOS,=Offline --env.CM_MLPERF_LOADGEN_MODES,=performance,accuracy --env.CM_OUTPUT_FOLDER_NAME=test_results --add_deps_recursive.compiler.tags=gcc --add_deps_recursive.submission-checker.tags=_short-run --add_deps_recursive.get-mlperf-inference-results-dir.tags=_version.r4_1-dev --add_deps_recursive.get-mlperf-inference-submission-dir.tags=_version.r4_1-dev --add_deps_recursive.mlperf-inference-nvidia-scratch-space.tags=_version.r4_1-dev --add_deps_recursive.mlperf-inference-implementation.tags=_batch_size.1 --adr.compiler.tags=gcc --adr.submission-checker.tags=_short-run --adr.get-mlperf-inference-results-dir.tags=_version.r4_1-dev --adr.get-mlperf-inference-submission-dir.tags=_version.r4_1-dev --adr.mlperf-inference-nvidia-scratch-space.tags=_version.r4_1-dev --v=False --print_env=False --print_deps=False --dump_version_info=True  --env.OUTPUT_BASE_DIR=/home/anandhu/gh_action_results  --env.CM_MLPERF_INFERENCE_SUBMISSION_DIR=/home/anandhu/gh_action_submissions  --docker_run_deps "
export CM_DOCKER_RUN_SCRIPT_TAGS="app,mlperf,inference,generic,_reference,_mixtral-8x7b,_pytorch,_cpu,_test,_r4.1-dev_default,_offline"
export CM_DOCKER_SHM_SIZE="32gb"
export CM_DOCKER_VOLUME_MOUNTS="['/home/anandhu/gh_action_results:/home/anandhu/gh_action_results', '/home/anandhu/gh_action_submissions:/home/anandhu/gh_action_submissions']"
export CM_ENV_NVMITTEN_DOCKER_WHEEL_PATH="/opt/nvmitten-0.1.3b0-cp38-cp38-linux_x86_64.whl"
export CM_HW_NAME="gh_action"
export CM_IMAGENET_ACCURACY_DTYPE="float32"
export CM_LIBRISPEECH_ACCURACY_DTYPE="float32"
export CM_MLOPS_REPO="anandhu-eng@cm4mlops"
export CM_MLPERF_BACKEND="pytorch"
export CM_MLPERF_CLEAN_ALL="True"
export CM_MLPERF_CLEAN_SUBMISSION_DIR="yes"
export CM_MLPERF_DEVICE="cpu"
export CM_MLPERF_IMPLEMENTATION="mlcommons_python"
export CM_MLPERF_INFERENCE_3DUNET_PATH="/home/anandhu/CM/repos/local/cache/3bdb110d76bb4958/inference/vision/medical_imaging/3d-unet-kits19"
export CM_MLPERF_INFERENCE_BERT_PATH="/home/anandhu/CM/repos/local/cache/3bdb110d76bb4958/inference/language/bert"
export CM_MLPERF_INFERENCE_CLASSIFICATION_AND_DETECTION_PATH="/home/anandhu/CM/repos/local/cache/3bdb110d76bb4958/inference/vision/classification_and_detection"
export CM_MLPERF_INFERENCE_CONF_PATH="/home/anandhu/CM/repos/local/cache/3bdb110d76bb4958/inference/mlperf.conf"
export CM_MLPERF_INFERENCE_DLRM_PATH="/home/anandhu/CM/repos/local/cache/3bdb110d76bb4958/inference/recommendation/dlrm"
export CM_MLPERF_INFERENCE_DLRM_V2_PATH="/home/anandhu/CM/repos/local/cache/3bdb110d76bb4958/inference/recommendation/dlrm_v2"
export CM_MLPERF_INFERENCE_GPTJ_PATH="/home/anandhu/CM/repos/local/cache/3bdb110d76bb4958/inference/language/gpt-j"
export CM_MLPERF_INFERENCE_RNNT_PATH="/home/anandhu/CM/repos/local/cache/3bdb110d76bb4958/inference/speech_recognition/rnnt"
export CM_MLPERF_INFERENCE_SOURCE="/home/anandhu/CM/repos/local/cache/3bdb110d76bb4958/inference"
export CM_MLPERF_INFERENCE_SUBMISSION_DIR="/home/anandhu/gh_action_submissions"
export CM_MLPERF_INFERENCE_VERSION="4.1-dev"
export CM_MLPERF_INFERENCE_VISION_PATH="/home/anandhu/CM/repos/local/cache/3bdb110d76bb4958/inference/inference/vision"
export CM_MLPERF_LAST_RELEASE="v4.0"
export CM_MLPERF_LOADGEN_ALL_MODES="yes"
export CM_MLPERF_LOADGEN_COMPLIANCE="no"
export CM_MLPERF_LOADGEN_EXTRA_OPTIONS=""
export CM_MLPERF_LOADGEN_MAX_BATCHSIZE="1"
export CM_MLPERF_LOADGEN_MODE="performance"
export CM_MLPERF_LOADGEN_MODES="['performance', 'accuracy']"
export CM_MLPERF_LOADGEN_SCENARIO="Offline"
export CM_MLPERF_LOADGEN_SCENARIOS="['Offline']"
export CM_MLPERF_LOADGEN_TARGET_QPS="1"
export CM_MLPERF_MODEL="mixtral-8x7b"
export CM_MLPERF_MODEL_EQUAL_ISSUE_MODE="yes"
export CM_MLPERF_MODEL_PRECISION="float32"
export CM_MLPERF_PYTHON="yes"
export CM_MLPERF_QUANTIZATION="False"
export CM_MLPERF_RUN_STYLE="test"
export CM_MLPERF_SUBMISSION_GENERATION_STYLE="short"
export CM_MLPERF_SUBMISSION_RUN="yes"
export CM_MLPERF_SUBMISSION_SYSTEM_TYPE="datacenter"
export CM_MLPERF_SUBMITTER="MLCommons"
export CM_MLPERF_USE_DOCKER="True"
export CM_MODEL="mixtral-8x7b"
export CM_OPENIMAGES_ACCURACY_DTYPE="float32"
export CM_OUTPUT_FOLDER_NAME="test_results"
export CM_QUIET="yes"
export CM_REAL_RUN="True"
export CM_REGENERATE_MEASURE_FILES="yes"
export CM_RERUN="yes"
export CM_RUN_MLPERF_ACCURACY="on"
export CM_RUN_MLPERF_INFERENCE_APP_DEFAULTS="r4.1-dev_default"
export CM_RUN_STATE_DOCKER="True"
export CM_RUN_SUBMISSION_CHECKER="yes"
export CM_SKIP_SYS_UTILS="yes"
export CM_SQUAD_ACCURACY_DTYPE="float32"
export CM_TAR_SUBMISSION_DIR="yes"
export CM_TEST_QUERY_COUNT="1"
export CM_TMP_CURRENT_PATH="/home/anandhu/CM/repos/anandhu-eng@cm4mlops/script/app-mlperf-inference"
export CM_TMP_CURRENT_SCRIPT_PATH="/home/anandhu/CM/repos/anandhu-eng@cm4mlops/script/build-docker-image"
export CM_TMP_CURRENT_SCRIPT_REPO_PATH="/home/anandhu/CM/repos/anandhu-eng@cm4mlops"
export CM_TMP_CURRENT_SCRIPT_REPO_PATH_WITH_PREFIX="/home/anandhu/CM/repos/anandhu-eng@cm4mlops"
export CM_TMP_CURRENT_SCRIPT_WORK_PATH="/home/anandhu/CM/repos/anandhu-eng@cm4mlops/script/app-mlperf-inference/dockerfiles"
export CM_TMP_PIP_VERSION_STRING=""
export OUTPUT_BASE_DIR="/home/anandhu/gh_action_results"


. "/home/anandhu/CM/repos/anandhu-eng@cm4mlops/script/build-docker-image/run.sh"
