FROM ubuntu:22.04

# Automatically generated by the CM workflow automation meta-framework
# https://github.com/mlcommons/ck

LABEL github=""
LABEL maintainer=""
LABEL license=""

SHELL ["/bin/bash", "-c"]

ARG UID=1000
ARG GID=1000
ARG CM_GH_TOKEN


# Notes: https://runnable.com/blog/9-common-dockerfile-mistakes
# Install system dependencies
RUN apt-get update -y
RUN apt-get install -y python3 python3-pip git sudo wget python3-venv

# Setup docker environment
ENTRYPOINT ["/bin/bash", "-c"]
ENV TZ="US/Pacific"
ENV PATH="${PATH}:/home/cmuser/.local/bin"
RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo $TZ >/etc/timezone

# Setup docker user
RUN groupadd -g $GID -o cm
RUN useradd -m -u $UID -g $GID -o --create-home --shell /bin/bash cmuser
RUN echo "cmuser ALL=(ALL) NOPASSWD: ALL" >> /etc/sudoers
USER cmuser:cm
WORKDIR /home/cmuser

# Install python packages
RUN python3 -m venv /home/cmuser/venv/cm 
ENV PATH="/home/cmuser/venv/cm/bin:$PATH"
RUN python3 -m pip install cmind requests giturlparse tabulate  

# Download CM repo for scripts
RUN cm pull repo anandhu-eng@cm4mlops --branch=jsontoyaml

# Install all system dependencies
RUN cm run script --tags=get,sys-utils-cm --quiet

# Run commands
RUN cm pull repo && cm run script --tags=app,mlperf,inference,generic,_reference,_mixtral-8x7b,_pytorch,_cpu,_test,_r4.1-dev_default,_offline --quiet=true --env.CM_QUIET=yes --env.CM_MLPERF_IMPLEMENTATION=reference --env.CM_MLPERF_MODEL=mixtral-8x7b --env.CM_MLPERF_RUN_STYLE=test --env.CM_MLPERF_BACKEND=pytorch --env.CM_MLPERF_LOADGEN_MAX_BATCHSIZE=1 --env.CM_MLPERF_SUBMISSION_SYSTEM_TYPE=datacenter --env.CM_MLPERF_CLEAN_ALL=True --env.CM_MLPERF_DEVICE=cpu --env.CM_MLPERF_USE_DOCKER=True --env.CM_HW_NAME=gh_action --env.OUTPUT_BASE_DIR=/home/anandhu/gh_action_results --env.CM_MLPERF_LOADGEN_SCENARIO=Offline --env.CM_MLPERF_INFERENCE_SUBMISSION_DIR=/home/anandhu/gh_action_submissions --env.CM_MLPERF_SUBMITTER=MLCommons --env.CM_MLPERF_LOADGEN_TARGET_QPS=1 --env.CM_TEST_QUERY_COUNT=1 --env.CM_MLPERF_LOADGEN_COMPLIANCE=no --env.CM_MLPERF_SUBMISSION_RUN=yes --env.CM_RUN_MLPERF_ACCURACY=on --env.CM_RUN_SUBMISSION_CHECKER=yes --env.CM_TAR_SUBMISSION_DIR=yes --env.CM_MLPERF_SUBMISSION_GENERATION_STYLE=short --env.CM_MLPERF_LOADGEN_ALL_MODES=yes --env.CM_MLPERF_INFERENCE_VERSION=4.1-dev --env.CM_RUN_MLPERF_INFERENCE_APP_DEFAULTS=r4.1-dev_default --env.CM_MLPERF_LAST_RELEASE=v4.0 --env.CM_MODEL=mixtral-8x7b --env.CM_MLPERF_CLEAN_SUBMISSION_DIR=yes --env.CM_RERUN=yes --env.CM_MLPERF_LOADGEN_EXTRA_OPTIONS= --env.CM_MLPERF_LOADGEN_MODE=performance --env.CM_MLPERF_LOADGEN_SCENARIOS,=Offline --env.CM_MLPERF_LOADGEN_MODES,=performance,accuracy --env.CM_OUTPUT_FOLDER_NAME=test_results --add_deps_recursive.compiler.tags=gcc --add_deps_recursive.submission-checker.tags=_short-run --add_deps_recursive.get-mlperf-inference-results-dir.tags=_version.r4_1-dev --add_deps_recursive.get-mlperf-inference-submission-dir.tags=_version.r4_1-dev --add_deps_recursive.mlperf-inference-nvidia-scratch-space.tags=_version.r4_1-dev --add_deps_recursive.mlperf-inference-implementation.tags=_batch_size.1 --adr.compiler.tags=gcc --adr.submission-checker.tags=_short-run --adr.get-mlperf-inference-results-dir.tags=_version.r4_1-dev --adr.get-mlperf-inference-submission-dir.tags=_version.r4_1-dev --adr.mlperf-inference-nvidia-scratch-space.tags=_version.r4_1-dev --v=False --print_env=False --print_deps=False --dump_version_info=True --quiet --fake_run --env.CM_RUN_STATE_DOCKER=True  
